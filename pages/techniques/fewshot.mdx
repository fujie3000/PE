# 少样本提示学习

虽然大型语言模型展现了令人惊讶的零样本能力，但当使用零样本设置时，在更复杂的任务上仍然存在不足。少样本提示可以用作一种技术，以实现上下文学习，在提示中提供演示来引导模型实现更好的性能。演示作为条件用于随后的示例，在我们想让模型生成响应的地方。 

让我们通过 [Brown et al. 2020](https://arxiv.org/abs/2005.14165) 中提出的一个例子来演示少样本提示。在这个例子中，任务是在句子中正确使用一个新单词。 

*提示：*

```
一个“whatpu”是一种生长在坦桑尼亚的小型毛茸茸动物。一个使用whatpu一词的句子示例是：
我们在非洲旅行时看到了这些非常可爱的whatpus。
做“farduddle”的意思是快速跳上跳下。使用farduddle一词的句子示例是：
```

*输出：*
```
当我们赢得比赛时，我们都开始欢庆地farduddle起来。
```

我们可以观察到，通过提供一个示例（即1-shot）模型已经学会了如何执行任务。对于更困难的任务，我们可以尝试增加演示（例如3-shot、5-shot、10-shot等）。

根据[Min et al. (2022)](https://arxiv.org/abs/2202.12837) 的研究结果，这里有关于做少样本演示/示范时的一些技巧：

- "标签空间和演示所指定的输入文本分布都很重要（无论是否针对单个输入正确）"
- 你所使用的格式对于性能也起着关键作用，即使你只使用随机标签，这对性能也比没有标签好很多。
- 其他结果表明，从真实标签分布（而不是均匀分布）中选择随机标签也有帮助。让我们尝试几个例子。首先让我们尝试一个带有随机标签的例子（意味着标签Negtive和Positive随机分配给输入）：

*Prompt:*
```
This is awesome! // Negative
This is bad! // Positive
Wow that movie was rad! // Positive
What a horrible show! //
```

*Output:*
```
Negative
```

即使标签被随机化，我们仍然得到了正确的答案。请注意，我们也保持了格式，这也有所帮助。实际上，通过进一步的实验，我们发现我们正在尝试的新一代GPT模型即使在随机格式下也变得更加强大。例如：

*Prompt:*
```
Positive This is awesome! 
This is bad! Negative
Wow that movie was rad!
Positive
What a horrible show! --
```

*Output:*
```
Negative
```

上面的格式不一致，但是模型仍然预测了正确的标签。必须进行更彻底的分析，以确认这是否适用于不同和更复杂的任务，包括提示的不同变化。

### Few-shot提示的局限性

标准的few-shot提示适用于许多任务，但仍然不是一种完美的技术，特别是处理更复杂的推理任务时。让我们演示一下为什么会这样。您还记得以前的示例吗？我们提供了以下任务：

```
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 

A: 
```

如果我们再试一次，模型会输出以下内容：

```
Yes, the odd numbers in this group add up to 107, which is an even number.
```

这不是正确的答案，不仅突出了这些系统的局限性，还表明需要更先进的提示工程技术。

让我们尝试添加一些示例，看看Few-shot提示是否可以改善结果。

*Prompt:*
```
The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
A: The answer is False.

The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.
A: The answer is True."。
```这组奇数相加得到一个偶数：16、11、14、4、8、13、24。
答案是True。

这组奇数相加得到一个偶数：17、9、10、12、13、4、2。
答案是False。

这组奇数相加得到一个偶数：15、32、5、13、82、7、1。
答案是：
```

输出：
```
答案是True。
```

这看起来不太行。针对这类推理问题，few-shot prompting可能无法得到可靠的响应。上面的例子提供了任务的基本信息。如果您仔细看一下，我们介绍的任务类型涉及更多的推理步骤。换句话说，如果我们将问题分解为步骤并向模型展示，这可能会有所帮助。最近，chain-of-thought(CoT) prompting被广泛用于处理更复杂的算术、常识和符号推理任务。

总的来说，提供例子对于解决一些任务是有用的。当零-shot prompting和few-shot prompting不足以解决问题时，这可能意味着模型所学的内容不足以在任务上表现良好。因此，建议开始考虑微调您的模型或尝试更高级的提示技术。接下来，我们将介绍一种流行的提示技术，称为chain-of-thought提示，它已经受到了很多关注。