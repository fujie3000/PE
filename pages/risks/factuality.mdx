# 真实性

LLM模型的结果往往听起来连贯和有力，但有时却是捏造出来的。改进提示可以帮助提高模型的准确性和真实性，并减少生成不一致和捏造的回复的可能性。

一些解决方案可能包括：
- 在上下文中提供真实事实（例如相关文章段落或维基百科条目），以减少模型生成虚假文本的可能性。
- 通过降低概率参数并指示其在不知道答案时承认（例如，“我不知道”）来配置模型以生成较少多样化的回复。
- 在提示中提供一个问题和回复的组合示例，以表明它可能知道和不知道的问题和回复。


让我们看一个简单的例子：

*提示：*
```
问：什么是原子？
答：原子是组成一切的微小粒子。

问：谁是阿尔文·蒙茨？
答：？

问：什么是Kozar-09？
答：？ 

问：火星有几个卫星？
答：火星有两个卫星，Phobos和Deimos。

问：谁是Neto Beto Roberto？
```

*输出：*
```
答：？
```

我捏造了“Neto Beto Roberto”的名字，所以模型在这种情况下是正确的。尝试稍微改变一下问题，看看是否可以让它工作。根据你目前已经学到的所有知识，还有不同的改进方法可以进一步提高它。